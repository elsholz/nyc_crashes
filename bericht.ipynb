{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics: NYC Crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "\n",
    "### Rahmenbedingungen des Projekts\n",
    "\n",
    "### Aufbau der Datenpipeline\n",
    "\n",
    "#### Installation der benötigten Docker-Container\n",
    "\n",
    "### Datenquelle\n",
    "\n",
    "### Analyseziele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation der Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kafka-python pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importieren benötigter Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from pymongo import MongoClient\n",
    "import datetime as dt\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herunterladen der Datensätze (H)\n",
    "Zum herunterladen der Datensätze werden die Daten von der Datenquelle mithilfe des nachfolgenden Python-Scripts heruntergeladen. Resultat sind drei `.csv`-Dateien die die Unfalldaten zeilenweise enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "for file_name, download_url in [\n",
    "    ('crashes.csv', 'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'),\n",
    "    ('vehicles.csv', 'https://data.cityofnewyork.us/api/views/bm4k-52h4/rows.csv?accessType=DOWNLOAD'),\n",
    "    ('persons.csv', 'https://data.cityofnewyork.us/api/views/f55k-p6yu/rows.csv?accessType=DOWNLOAD'),\n",
    "]:\n",
    "    if not os.path.isfile(fp:= (Path('data') / file_name)):\n",
    "        with open(fp, 'wb') as crash_file:\n",
    "            crash_file.write(requests.get(download_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten und senden über den Producer (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird der Producer erstellt, sodass dieser verwendet werden kann, um Daten zu senden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier nur einlesen von Testdaten, das muss dann weg (die anderen dauern aber ewig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('Motor_Vehicle_Collisions_-_Crashes.csv', encoding='utf-8')\n",
    "rows = dataset.readlines()[1:]\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "        producer.send('nyc_crashes', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einlesen der Crashes (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achtung: Viele Datensätze, dauert einige Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('data/crashes.csv', encoding='utf-8')\n",
    "rows = dataset.readlines()[1:]\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "        producer.send('nyc_crashes', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einlesen der Fahrzeuge (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achtung: Viele Datensätze, dauert einige Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('data/vehicles.csv', encoding='utf-8')\n",
    "rows = dataset.readlines()[1:]\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "        producer.send('nyc_crashes', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einlesen der Personen (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achtung: Viele Datensätze, dauert einige Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('data/persons.csv', encoding='utf-8')\n",
    "rows = dataset.readlines()[1:]\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "        producer.send('nyc_crashes', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesen der Daten mit dem Consumer und Import in die Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "\n",
    "crashes = client['nyc_crashes']['crashes']\n",
    "crashes.delete_many({})\n",
    "\n",
    "consumer = KafkaConsumer('nyc_crashes', bootstrap_servers=['localhost:9092'], auto_offset_reset=\"earliest\")\n",
    "\n",
    "for row in consumer: \n",
    "    row = row.value.decode('utf-8').split(',')\n",
    "    try:\n",
    "        res = {}\n",
    "        for idx, (db_field, field_type) in enumerate([\n",
    "            ('crash_date', str), \n",
    "            ('crash_time', str), \n",
    "            ('borough', str), \n",
    "            ('zip_code', int), \n",
    "            ('latitude', float), \n",
    "            ('longitude', float), \n",
    "            ('location', str), \n",
    "            ('on_street_name', str), \n",
    "            ('cross_street_name', str), \n",
    "            ('off_street_name', str), \n",
    "            ('persons_injured', int), \n",
    "            ('persons_killed', int), \n",
    "            ('pedestrians_injured', int), \n",
    "            ('pedestrians_killed', int), \n",
    "            ('cyclists_injured', int), \n",
    "            ('cyclists_killed', int), \n",
    "            ('motorists_injured', int), \n",
    "            ('motorists_killed', int), \n",
    "            ('contributing_factor_vehicle_1', str),\n",
    "            ('contributing_factor_vehicle_2', str),\n",
    "            ('contributing_factor_vehicle_3', str),\n",
    "            ('contributing_factor_vehicle_4', str),\n",
    "            ('contributing_factor_vehicle_5', str),\n",
    "            ('_id', int),\n",
    "            ('vehicle_type_code_1', str),\n",
    "            ('vehicle_type_code_2', str),\n",
    "            ('vehicle_type_code_3', str),\n",
    "            ('vehicle_type_code_4', str),\n",
    "            ('vehicle_type_code_5', str),\n",
    "        ]):\n",
    "            if row_data := row[idx]:\n",
    "                res[db_field] = field_type.__call__(row_data) if not isinstance(row_data, field_type) else row_data\n",
    "\n",
    "        res['vehicles'] = []\n",
    "        res['persons'] = []\n",
    "        crashes.insert_one(res)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "for i in range(1, 13):\n",
    "    if i < 10:\n",
    "        i = \"0%s\" % i\n",
    "    dataset = open('./data/2019/yellow-cabs-2019-%s.csv' % i, encoding='utf-8')\n",
    "    rows = dataset.readlines()[1:]\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        producer.send('yellow-cabs', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    if i < 10:\n",
    "        i = \"0%s\" % i\n",
    "    dataset = open('./data/2019/yellow-cabs-2020-%s.csv' % i, encoding='utf-8')\n",
    "    rows = dataset.readlines()[1:]\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        producer.send('yellow-cabs', value=bytearray(row, encoding='utf-8'), key=bytearray(str(i), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "consumer = KafkaConsumer('yellow-cabs', bootstrap_servers=[\"\"])\n",
    "\n",
    "client = MongoClient(\"\")\n",
    "\n",
    "yellow_collection = client['datawarehouse']['bg-yellowcabs']\n",
    "yellow_collection.delete_many({})\n",
    "\n",
    "count = 0\n",
    "\n",
    "for msg in consumer: \n",
    "    count += 1\n",
    "    print('Received new message: %s' % count)\n",
    "    values = msg.value.decode('utf-8').split(',')\n",
    "    \n",
    "    yellow_collection.insert_one({\n",
    "        'pickup_datetime': dt.datetime.strptime(values[1], \"%Y-%m-%d %H:%M:%S\"),\n",
    "        'dropoff_datetime': dt.datetime.strptime(values[2], \"%Y-%m-%d %H:%M:%S\"),\n",
    "        'passenger_count': int(values[3]),\n",
    "        'trip_distance': float(values[4]),\n",
    "        'PULocationID': values[5],\n",
    "        'DOLocationID': values[6],\n",
    "        'payment_type': int(values[9]),\n",
    "        'fare_amount': float(values[10]),\n",
    "        'tip_amount': float(values[15]),\n",
    "        'total_amount': float(values[16])\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
